{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets(features, target):\n",
    "    \"\"\"\n",
    "    Combina las características y el objetivo en un solo DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    features (pd.DataFrame): DataFrame de características.\n",
    "    target (pd.DataFrame): DataFrame del objetivo.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame combinado.\n",
    "    \"\"\"\n",
    "    return pd.concat([features.reset_index(drop=True), target.reset_index(drop=True)], axis=1)\n",
    "\n",
    "def remove_low_correlation_columns(data, target_column, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Elimina columnas con correlación baja respecto a la columna objetivo.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame con las características y la columna objetivo.\n",
    "    target_column (str): Nombre de la columna objetivo.\n",
    "    threshold (float): Umbral de correlación.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame sin las columnas de baja correlación.\n",
    "    list: Lista de columnas eliminadas.\n",
    "    \"\"\"\n",
    "    correlation_matrix = data.corr()\n",
    "    correlation_with_target = correlation_matrix[target_column].abs()\n",
    "    columns_to_remove = correlation_with_target[correlation_with_target < threshold].index.tolist()\n",
    "    \n",
    "    if target_column in columns_to_remove:\n",
    "        columns_to_remove.remove(target_column)\n",
    "\n",
    "    return data.drop(columns=columns_to_remove), columns_to_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_target_encoding(features, target, encode_col, n_splits=5):\n",
    "    # Crear una serie vacía para almacenar los valores codificados\n",
    "    encoded_values = pd.Series(index=features.index, dtype='float64')\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(features):\n",
    "        train_data, val_data = features.iloc[train_idx], features.iloc[val_idx]\n",
    "        fraud_rate = target.iloc[train_idx].groupby(train_data[encode_col]).mean()\n",
    "        # Utilizar fillna(0) para evitar problemas con valores no mapeados\n",
    "        encoded_values.iloc[val_idx] = val_data[encode_col].map(fraud_rate).fillna(0)\n",
    "    \n",
    "    # Asignar los valores codificados a la nueva columna en features\n",
    "    features[f'{encode_col}_encoded'] = encoded_values\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "La función haversine calcula la distancia entre dos puntos en la \n",
    "superficie de la Tierra dados sus valores de latitud y longitud.\n",
    "\n",
    "'''\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radio de la Tierra en kilómetros\n",
    "    R = 6371\n",
    "    \n",
    "    # Convertir la diferencia de latitudes y longitudes de grados a radianes\n",
    "    dlat = np.radians(lat2 - lat1)  # Diferencia de latitudes\n",
    "    dlon = np.radians(lon2 - lon1)  # Diferencia de longitudes\n",
    "    \n",
    "    # Aplicar la fórmula del haversine para calcular la distancia\n",
    "    a = (np.sin(dlat / 2) ** 2 +  # Cálculo del primer término de la fórmula\n",
    "         np.cos(np.radians(lat1)) *  # Cálculo del coseno de la latitud 1\n",
    "         np.cos(np.radians(lat2)) *  # Cálculo del coseno de la latitud 2\n",
    "         np.sin(dlon / 2) ** 2)  # Cálculo del segundo término de la fórmula\n",
    "    \n",
    "    # Cálculo del ángulo central en radianes\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    \n",
    "    # Calcular la distancia entre los dos puntos utilizando el radio de la Tierra\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance  # Retornar la distancia calculada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:/Users/Jose Castro/Desktop/FINAL NO COUNTRY/c21-47-ft-data-bi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"data/intermediate/data_eda.csv\"\n",
    "data_proc = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_selec = ['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt',\n",
    "       'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat',\n",
    "       'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat',\n",
    "       'merch_long', 'is_fraud', 'merch_zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 38 columns):\n",
      " #   Column                         Non-Null Count    Dtype  \n",
      "---  ------                         --------------    -----  \n",
      " 0   trans_date_trans_time          1296675 non-null  object \n",
      " 1   cc_num                         1296675 non-null  int64  \n",
      " 2   merchant                       1296675 non-null  object \n",
      " 3   category                       1296675 non-null  object \n",
      " 4   amt                            1296675 non-null  float64\n",
      " 5   first                          1296675 non-null  object \n",
      " 6   last                           1296675 non-null  object \n",
      " 7   gender                         1296675 non-null  object \n",
      " 8   street                         1296675 non-null  object \n",
      " 9   city                           1296675 non-null  object \n",
      " 10  state                          1296675 non-null  object \n",
      " 11  zip                            1296675 non-null  int64  \n",
      " 12  lat                            1296675 non-null  float64\n",
      " 13  long                           1296675 non-null  float64\n",
      " 14  city_pop                       1296675 non-null  int64  \n",
      " 15  job                            1296675 non-null  object \n",
      " 16  dob                            1296675 non-null  object \n",
      " 17  trans_num                      1296675 non-null  object \n",
      " 18  unix_time                      1296675 non-null  object \n",
      " 19  merch_lat                      1296675 non-null  float64\n",
      " 20  merch_long                     1296675 non-null  float64\n",
      " 21  is_fraud                       1296675 non-null  int64  \n",
      " 22  merch_zipcode                  1100702 non-null  float64\n",
      " 23  age                            1296675 non-null  int64  \n",
      " 24  age_classification             1296139 non-null  object \n",
      " 25  distance                       1296675 non-null  float64\n",
      " 26  amount_per_transaction         1296675 non-null  float64\n",
      " 27  amount_per_age                 1296675 non-null  float64\n",
      " 28  days_since_last_transaction    1296675 non-null  float64\n",
      " 29  total_spent                    1296675 non-null  float64\n",
      " 30  amount_diff                    1296675 non-null  float64\n",
      " 31  transaction_count              1296675 non-null  int64  \n",
      " 32  amount_frequency_ratio         1296675 non-null  float64\n",
      " 33  time_diff                      1296675 non-null  float64\n",
      " 34  age_amount_interaction         1296675 non-null  float64\n",
      " 35  transaction_count_by_merchant  1296675 non-null  int64  \n",
      " 36  nunique_category               1296675 non-null  int64  \n",
      " 37  day_of_week                    1296675 non-null  object \n",
      "dtypes: float64(15), int64(8), object(15)\n",
      "memory usage: 375.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_proc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   trans_date_trans_time  1296675 non-null  object \n",
      " 1   cc_num                 1296675 non-null  int64  \n",
      " 2   merchant               1296675 non-null  object \n",
      " 3   category               1296675 non-null  object \n",
      " 4   amt                    1296675 non-null  float64\n",
      " 5   first                  1296675 non-null  object \n",
      " 6   last                   1296675 non-null  object \n",
      " 7   gender                 1296675 non-null  object \n",
      " 8   street                 1296675 non-null  object \n",
      " 9   city                   1296675 non-null  object \n",
      " 10  state                  1296675 non-null  object \n",
      " 11  zip                    1296675 non-null  int64  \n",
      " 12  lat                    1296675 non-null  float64\n",
      " 13  long                   1296675 non-null  float64\n",
      " 14  city_pop               1296675 non-null  int64  \n",
      " 15  job                    1296675 non-null  object \n",
      " 16  dob                    1296675 non-null  object \n",
      " 17  trans_num              1296675 non-null  object \n",
      " 18  unix_time              1296675 non-null  object \n",
      " 19  merch_lat              1296675 non-null  float64\n",
      " 20  merch_long             1296675 non-null  float64\n",
      " 21  is_fraud               1296675 non-null  int64  \n",
      " 22  merch_zipcode          1100702 non-null  float64\n",
      "dtypes: float64(6), int64(4), object(13)\n",
      "memory usage: 227.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Dejamos el dataset con las columnas iniciales\n",
    "data_proc_copy = data_proc[columns_selec]\n",
    "data_proc_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_proc_copy.drop(columns=[\"is_fraud\"],axis=1)\n",
    "target = data_proc_copy.is_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna de fecha y hora de transacción a formato datetime\n",
    "features['trans_date_trans_time'] = pd.to_datetime(features['trans_date_trans_time'], errors='coerce')\n",
    "\n",
    "# Extraer componentes de la fecha y hora\n",
    "features['year'] = features['trans_date_trans_time'].dt.year        # Año de la transacción\n",
    "features['month'] = features['trans_date_trans_time'].dt.month      # Mes de la transacción\n",
    "features['day'] = features['trans_date_trans_time'].dt.day          # Día del mes\n",
    "features['day_of_week'] = features['trans_date_trans_time'].dt.dayofweek  # Día de la semana (0=lunes, 6=domingo)\n",
    "features['hour'] = features['trans_date_trans_time'].dt.hour        # Hora de la transacción\n",
    "\n",
    "# Convertir la columna de fecha de nacimiento a formato datetime\n",
    "features['dob'] = pd.to_datetime(features['dob'])\n",
    "\n",
    "# Calcular la edad a partir de la fecha de nacimiento\n",
    "features['age'] = np.floor((pd.Timestamp.now() - features['dob']).dt.days / 365.25).astype(\"int64\")\n",
    "\n",
    "# Calcular la distancia entre las coordenadas de la transacción y las del comerciante\n",
    "features['distance'] = features.apply(lambda row: haversine(row['lat'], row['long'], row['merch_lat'], row['merch_long']), axis=1)\n",
    "\n",
    "# Calcular la media y el total gastado por cada número de tarjeta de crédito\n",
    "features['amount_per_transaction'] = features.groupby('cc_num')['amt'].transform('mean')  # Promedio por transacción\n",
    "features['amount_per_age'] = features['amt'] / features['age']\n",
    "# Contar el número de transacciones por número de tarjeta de crédito\n",
    "features['transaction_count'] = features.groupby('cc_num')['cc_num'].transform('count')\n",
    "\n",
    "# Se crea columna relacion entre el monto y la frecuencia de uso\n",
    "features['amount_frequency_ratio'] = features['amount_per_transaction'] / features['transaction_count']\n",
    "# Se crea columna diferencia de monto respecto al promedio\n",
    "features['amount_diff'] = features['amt'] - features.groupby('cc_num')['amt'].transform('mean')\n",
    "\n",
    "features['total_spent'] = features.groupby('cc_num')['amt'].transform('sum')  # Total gastado\n",
    "\n",
    "\n",
    "# Calcular la relación entre el número de transacciones y la edad\n",
    "features['age_transaction_ratio'] = features['transaction_count'] / features['age']\n",
    "\n",
    "# Calcular la interacción entre edad y monto de transacción\n",
    "features['age_amount_interaction'] = features['age'] * features['amt']\n",
    "\n",
    "# Volver a convertir la columna de fecha y hora (si es necesario)\n",
    "features['trans_date_trans_time'] = pd.to_datetime(features['trans_date_trans_time'])\n",
    "\n",
    "# Calcular días desde la última transacción\n",
    "features['days_since_last_transaction'] = features.groupby('cc_num')['trans_date_trans_time'].diff().dt.days.fillna(0)\n",
    "\n",
    "# Calcular el promedio de días entre transacciones\n",
    "features['avg_days_between_transactions'] = features.groupby('cc_num')['days_since_last_transaction'].transform('mean')\n",
    "\n",
    "# Calcular la frecuencia de estado y categoría\n",
    "state_freq = features['state'].value_counts().to_dict()\n",
    "features['state_freq'] = features['state'].map(state_freq)\n",
    "\n",
    "category_freq = features['category'].value_counts().to_dict()\n",
    "features['category_freq'] = features['category'].map(category_freq)\n",
    "\n",
    "merchant_freq = features['merchant'].value_counts().to_dict()\n",
    "features['merchant_freq'] = features['merchant'].map(merchant_freq)\n",
    "\n",
    "# Aplicar KFold target encoding\n",
    "columns_to_encode = ['job']\n",
    "for col in columns_to_encode:\n",
    "    if col in features.columns:\n",
    "        features = kfold_target_encoding(features, target, col)\n",
    "    else:\n",
    "        print(f\"La columna {col} no existe en features.\")\n",
    "\n",
    "# Calcular la frecuencia de categoría y comerciante en datos no fraudulentos\n",
    "category_freq_non_fraud = features['category'].value_counts().to_dict()\n",
    "features['category_freq_non_fraud'] = features['category'].map(category_freq_non_fraud)\n",
    "\n",
    "merchant_freq_non_fraud = features['merchant'].value_counts().to_dict()\n",
    "features['merchant_freq_non_fraud'] = features['merchant'].map(merchant_freq_non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_option_A = [\"cc_num\", \"merchant\", \"category\", \"first\", \"last\", \"street\", \"city\", \"city_pop\", \n",
    "                    \"city_pop_group\", \"zip\", \"lat\", \"long\", \"job\", \"dob\", \"unix_time\", \"merch_lat\", \n",
    "                    \"merch_long\", \"merch_zipcode\", \"age\", \"trans_date_trans_time\", \"trans_num\"]\n",
    "\n",
    "columns_option_B = [\"cc_num\", \"merchant\", \"category\", \"first\", \"last\", \"street\", \"city\", \"city_pop\", \n",
    "                    \"city_pop_group\", \"zip\", \"lat\", \"long\", \"job\", \"dob\", \"unix_time\", \"merch_lat\", \n",
    "                    \"merch_long\", \"merch_zipcode\", \"age\", \"trans_date_trans_time\", \"state\", \n",
    "                    \"age_classification\", \"age_classification_transaction_ratio\", \"time_diff\", \n",
    "                    \"category_encoded\", \"merchant_encoded\", \"city_pop_group_encoded\", \"trans_num\"]\n",
    "\n",
    "columns_option_C = [\"amt\", \"amount_per_transaction\", \"amount_per_age\", \"amount_diff\", \n",
    "                    \"amount_frequency_ratio\", \"age_amount_interaction\"]\n",
    "\n",
    "columns_option_D = ['amt', 'year', 'month', 'day', 'day_of_week', 'hour', 'distance',\n",
    "                    'amount_per_transaction', 'total_spent', 'transaction_count',\n",
    "                    'age_transaction_ratio', 'age_amount_interaction', \"gender\",\n",
    "                    'days_since_last_transaction', 'avg_days_between_transactions',\n",
    "                    'state_freq', 'category_freq', 'merchant_freq', 'job_encoded',\n",
    "                    'category_freq_non_fraud', 'merchant_freq_non_fraud', 'gender_M',\n",
    "                    'is_fraud']\n",
    "\n",
    "\n",
    "def eliminar_columnas(data, opcion):\n",
    "    # Definir opciones en un diccionario con el nombre y las columnas a eliminar o mantener\n",
    "    opciones = {\n",
    "        'A': (\"Opción A\", columns_option_A),\n",
    "        'B': (\"Opción B\", columns_option_B),\n",
    "        'C': (\"Opción C (mantener solo estas columnas)\", columns_option_C),\n",
    "        'D': (\"Opción D (mantener solo estas columnas)\", columns_option_D)\n",
    "    }\n",
    "    \n",
    "    # Validar la opción seleccionada\n",
    "    if opcion in opciones:\n",
    "        nombre_opcion, columns = opciones[opcion]\n",
    "        print(f\"Aplicando {nombre_opcion}\")\n",
    "    else:\n",
    "        print(\"Opción no válida. Elige 'A', 'B', 'C', o 'D'.\")\n",
    "        return data  # Devuelve el DataFrame sin cambios si la opción no es válida\n",
    "    \n",
    "    # Aplicar según la opción\n",
    "    if opcion in ['C', 'D']:\n",
    "        # Mantener solo las columnas especificadas si existen en el DataFrame\n",
    "        data = data[data.columns.intersection(columns)]\n",
    "    else:\n",
    "        # Eliminar columnas especificadas si existen en el DataFrame\n",
    "        data = data.drop(columns=[col for col in columns if col in data.columns], errors='ignore')\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando Opción A\n",
      "Aplicando Opción B\n",
      "Aplicando Opción C (mantener solo estas columnas)\n",
      "Aplicando Opción D (mantener solo estas columnas)\n"
     ]
    }
   ],
   "source": [
    "result_A = eliminar_columnas(features, 'A')\n",
    "result_B = eliminar_columnas(features, 'B')\n",
    "result_C = eliminar_columnas(features,'C')\n",
    "result_D = eliminar_columnas(features,'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = result_A.select_dtypes(include=['object']).columns\n",
    "feautres_encoded_A = pd.get_dummies(result_A, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "combined_data_A = combine_datasets(feautres_encoded_A, target)\n",
    "features_encoded_cleaned_A, removed_columns = remove_low_correlation_columns(combined_data_A, 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = result_B.select_dtypes(include=['object']).columns\n",
    "feautres_encoded_B = pd.get_dummies(result_B, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "combined_data_B = combine_datasets(feautres_encoded_B, target)\n",
    "features_encoded_cleaned_B, removed_columns = remove_low_correlation_columns(combined_data_B, 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = result_C.select_dtypes(include=['object']).columns\n",
    "feautres_encoded_C = pd.get_dummies(result_C, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "combined_data_C = combine_datasets(feautres_encoded_C, target)\n",
    "features_encoded_cleaned_C, removed_columns = remove_low_correlation_columns(combined_data_C, 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = result_D.select_dtypes(include=['object']).columns\n",
    "feautres_encoded_D = pd.get_dummies(result_D, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "combined_data_D = combine_datasets(feautres_encoded_D, target)\n",
    "features_encoded_cleaned_D, removed_columns = remove_low_correlation_columns(combined_data_D, 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se exporta el dataset modificado\n",
    "features_encoded_cleaned_D.to_feather('data_final_0') # Tiene 5 columnas\n",
    "\n",
    "features_encoded_cleaned_A.to_feather('data_final_1') # Tiene 6 columnas\n",
    "\n",
    "features_encoded_cleaned_C.to_feather('data_final_2') # Tiene 7 columnas\n",
    "\n",
    "combined_data_D.to_feather('data_final_3') # Tiene 22 columnas\n",
    "\n",
    "combined_data_B.to_feather('data_final_4') # Tiene 25 Columnas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
